# -*- coding: utf-8 -*-
"""Data Cleaning and Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MrBAHCsDd-4buu1-9sS0QltN3l67PgLA
"""

__author__ = "Leandro Ruiz"
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from scipy import stats
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error
from IPython.display import display
from IPython.html import widgets 
from IPython.display import display
from ipywidgets import interact, interactive, fixed, interact_manual
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV

from google.colab import drive

"""Ingresando al archivo directamente desde Drive:"""

drive.mount('/content/drive')
autofile = '/content/drive/My Drive/Datasets/cars.csv'
cars = pd.read_csv(autofile, header = None)

"""#Cleaning the dataset

Añadiendo titulos a las columnas:
"""

headers = ["symboling","normalized-losses","make","fuel-type","aspiration", "num-of-doors","body-style",
         "drive-wheels","engine-location","wheel-base", "length","width","height","curb-weight","engine-type",
         "num-of-cylinders", "engine-size","fuel-system","bore","stroke","compression-ratio","horsepower",
         "peak-rpm","city-mpg","highway-mpg","price"]
cars.columns = headers
cars.head()

"""Reemplazando datos perdidos con NaN, cambiando el tipo de datos, eliminando las filas que carecen de precios y contando datos perdidos por columnas:"""

cars.replace("?", np.nan, inplace = True)

cars[['bore', 'stroke']] = cars[['bore', 'stroke']].astype(float)
cars[['normalized-losses']] = cars[['normalized-losses']].astype(float)
cars[['price']] = cars[['price']].astype(float)
cars[['peak-rpm']] = cars[['peak-rpm']].astype(float)
cars[['horsepower']] = cars[['horsepower']].astype(float)

cars.dropna(subset=['price'], axis = 0, inplace= True)
cars.reset_index(drop = True, inplace = True)
missing_data = cars.isnull()

for column in missing_data.columns.values.tolist():
  print(column)
  print(missing_data[column].value_counts())
  print('')

"""Reemplazando valores perdidos:"""

avg_norm_losses = cars['normalized-losses'].astype(float).mean(axis = 0)
cars['normalized-losses'].replace(np.nan, avg_norm_losses, inplace = True)

avg_bore = cars['bore'].astype(float).mean(axis = 0)
cars['bore'].replace(np.nan, avg_bore, inplace = True)

avg_stroke = cars['stroke'].astype(float).mean(axis = 0)
cars['stroke'].replace(np.nan, avg_stroke, inplace = True)

avg_horsepower = cars['horsepower'].astype(float).mean(axis = 0)
cars['horsepower'].replace(np.nan, avg_horsepower, inplace = True)

cars['num-of-doors'].replace(np.nan, 'four', inplace = True)

cars.describe(include=[np.object])

"""#LAB 3"""

cars.dtypes

"""Correlacion entre variables:"""

cars[['bore', 'stroke', 'compression-ratio', 'horsepower']].corr()

"""Correlacion grafica entre variables:"""

sns.regplot(x = 'horsepower', y = 'price', data = cars)

"""Variables categoricas, sirve para ver el spread en objectos"""

sns.boxplot(x="body-style", y="price", data = cars)

"""Contar valores de una columna de tipo object"""

drive_wheels_counts = cars['drive-wheels'].value_counts().to_frame()
# change the name to the value conuts column
drive_wheels_counts.rename(columns={'drive-wheels': 'value_counts'}, inplace=True)
# change the name to the index
drive_wheels_counts.index.name = 'drive-wheels'
drive_wheels_counts

"""Usar groupby() para ver el precio promedio segun el tipo de traccion"""

cars_group_one = cars[['drive-wheels','price']]
cars_group_one = cars_group_one.groupby(['drive-wheels'],as_index=False).mean()
cars_group_one

"""Precio promedio combinando dos categorias:"""

cars_gptest = cars[['drive-wheels','body-style','price']]
grouped_test1 = cars_gptest.groupby(['drive-wheels','body-style'],as_index=False).mean()
grouped_test1

"""Heatmap con los datos de arriba:"""

grouped_pivot = grouped_test1.pivot(index='drive-wheels',columns='body-style')

fig, ax = plt.subplots()
im = ax.pcolor(grouped_pivot, cmap='RdBu')

#label names
row_labels = grouped_pivot.columns.levels[1]
col_labels = grouped_pivot.index

#move ticks and labels to the center
ax.set_xticks(np.arange(grouped_pivot.shape[1]) + 0.5, minor=False)
ax.set_yticks(np.arange(grouped_pivot.shape[0]) + 0.5, minor=False)

#insert labels
ax.set_xticklabels(row_labels, minor=False)
ax.set_yticklabels(col_labels, minor=False)

#rotate label if too long
plt.xticks(rotation=90)

fig.colorbar(im)
plt.show()

"""**P-VALUE**"""

pearson_coef, p_value = stats.pearsonr(cars['wheel-base'], cars['price'])
print("The Pearson Correlation Coefficient is", pearson_coef, " with a P-value of P =", p_value)

"""**ANOVA**"""

grouped_test2 = cars_gptest[['drive-wheels', 'price']].groupby(['drive-wheels'])

f_val, p_val = stats.f_oneway(grouped_test2.get_group('fwd')['price'], grouped_test2.get_group('rwd')['price'], grouped_test2.get_group('4wd')['price'])  
print( "ANOVA results: F=", f_val, ", P =", p_val)

"""#LAB 4

Simple linear regression model:
"""

lm = LinearRegression()
Z = cars[['horsepower', 'highway-mpg', 'engine-size']]

lm.fit(Z, cars['price'])

lm.intercept_

lm.coef_

Yhat = lm.predict(Z)
Yhat[0:5]

"""Regression plot between highway-mpg and price:"""

width = 12
height = 10
plt.figure(figsize=(width, height))
sns.regplot(x="highway-mpg", y="price", data = cars)
plt.ylim(0,)

"""Residual plot:"""

width = 12
height = 10
plt.figure(figsize=(width, height))
sns.residplot(cars['highway-mpg'], cars['price'])
plt.show()

"""Podemos ver que los residuos no se distribuyen aleatoriamente alrededor del eje x, lo que nos lleva a creer que quizás un modelo no lineal sea más apropiado para estos datos. Ver PlotPolly para los resultados finales."""

plt.figure(figsize = (10, 12))

ax1 = sns.distplot(cars['price'], hist=False, color="r", label="Actual Value")
sns.distplot(Yhat, hist=False, color="b", label="Fitted Values" , ax=ax1)

plt.title('Actual vs Fitted Values for Price')
plt.xlabel('Price (in dollars)')
plt.ylabel('Proportion of Cars')

plt.show()
plt.close()

def PlotPolly(model, independent_variable, dependent_variabble, Name):
    x_new = np.linspace(15, 55, 100)
    y_new = model(x_new)

    plt.plot(independent_variable, dependent_variabble, '.', x_new, y_new, '-')
    plt.title('Polynomial Fit with Matplotlib for Price ~ Length')
    ax = plt.gca()
    ax.set_facecolor((0.898, 0.898, 0.898))
    fig = plt.gcf()
    plt.xlabel(Name)
    plt.ylabel('Price of Cars')

    plt.show()
    plt.close()

x = cars['highway-mpg']
y = cars['price']

f = np.polyfit(x, y, 3)
p = np.poly1d(f)

PlotPolly(p, x, y, 'Highway MPG')

"""Cambiando el polinomio a uno de onceavo orden:"""

f1 = np.polyfit(x, y, 11)
p1 = np.poly1d(f1)
print(p1)
PlotPolly(p1, x, y, 'length')

"""Pipelines:"""

Input = [('scale',StandardScaler()), ('polynomial', PolynomialFeatures(include_bias=False)), ('model',LinearRegression())]

pipe = Pipeline(Input)
pipe

pipe.fit(Z,y)

ypipe = pipe.predict(Z)
ypipe[0:4]

"""**Measuring accuracy**

R-squared (the higher the best):
"""

# highway_mpg_fit
lm.fit(Z, y)
# Find the R^2
print('The R-square is: ', lm.score(Z, y))

"""MSE (the smallest the best):"""

Yhat = lm.predict(Z)
print('The output of the first four predicted value is: ', Yhat[0:4])

mse = mean_squared_error(f['price'], Yhat)
print('The mean square error of price and predicted value is: ', mse)

"""#LAB 5: Model Evaluation and Refinement

For evaluating the models we have to use numeric data only:
"""

cars_numeric = cars._get_numeric_data()

def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):
    width = 12
    height = 10
    plt.figure(figsize=(width, height))

    ax1 = sns.distplot(RedFunction, hist=False, color="r", label=RedName)
    ax2 = sns.distplot(BlueFunction, hist=False, color="b", label=BlueName, ax=ax1)

    plt.title(Title)
    plt.xlabel('Price (in dollars)')
    plt.ylabel('Proportion of Cars')

    plt.show()
    plt.close()

def PollyPlot(xtrain, xtest, y_train, y_test, lr,poly_transform):
    width = 12
    height = 10
    plt.figure(figsize=(width, height))
    
    
    #training data 
    #testing data 
    # lr:  linear regression object 
    #poly_transform:  polynomial transformation object 
 
    xmax=max([xtrain.values.max(), xtest.values.max()])

    xmin=min([xtrain.values.min(), xtest.values.min()])

    x=np.arange(xmin, xmax, 0.1)


    plt.plot(xtrain, y_train, 'ro', label='Training Data')
    plt.plot(xtest, y_test, 'go', label='Test Data')
    plt.plot(x, lr.predict(poly_transform.fit_transform(x.reshape(-1, 1))), label='Predicted Function')
    plt.ylim([-10000, 60000])
    plt.ylabel('Price')
    plt.legend()

"""Split data between training and testing.
The Y data is the predictible data, in this case the price. The X data is all te other variables.
"""

y_data = cars['price']
x_data = cars.drop('price', axis = 1)

x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.15, random_state=1)


print("number of test samples :", x_test.shape[0])
print("number of training samples:",x_train.shape[0])

lre = LinearRegression()

lre.fit(x_train[["horsepower"]], y_train)

lre.score(x_test[['horsepower']], y_test)

lre.score(x_train[['horsepower']], y_train)

"""Cross validation score"""

Rcross = cross_val_score(lre, x_data[['horsepower']], y_data, cv=4)
Rcross

print("The mean of the folds are", Rcross.mean(), "and the standard deviation is" , Rcross.std())

"""Negative squared error"""

-1 * cross_val_score(lre,x_data[['horsepower']], y_data,cv=4,scoring='neg_mean_squared_error')

Rc = cross_val_score(lre, x_data[['horsepower']], y_data, cv = 2)
Rc

"""Prediction of the cross validation score"""

from sklearn.model_selection import cross_val_predict

yhat = cross_val_predict(lre,x_data[['horsepower']], y_data,cv=4)
yhat[0:5]

"""**MODEL SELECTION**"""

lr = LinearRegression()
lr.fit(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_train)

yhat_train = lr.predict(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])
yhat_train[0:5]

yhat_test = lr.predict(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])
yhat_test[0:5]

Title = 'Distribution  Plot of  Predicted Value Using Training Data vs Training Data Distribution'
DistributionPlot(y_train, yhat_train, "Actual Values (Train)", "Predicted Values (Train)", Title)

"""Esto pasa cuando el grafico encuentra nueva data en el set de prueba, tiene muchos errores en las predicciones:"""

Title='Distribution  Plot of  Predicted Value Using Test Data vs Data Distribution of Test Data'
DistributionPlot(y_test,yhat_test,"Actual Values (Test)","Predicted Values (Test)",Title)

"""Overfitting"""

# usar el 55 % de la data para pruebas
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.45, random_state=0)

# crear un polinomio de 5to orden con la caracteristica 'horsepower'
pr = PolynomialFeatures(degree=5)
x_train_pr = pr.fit_transform(x_train[['horsepower']])
x_test_pr = pr.fit_transform(x_test[['horsepower']])
pr

# crear una regresion lineal
poly = LinearRegression()
poly.fit(x_train_pr, y_train)

# predicciones
yhat = poly.predict(x_test_pr)
yhat[0:5]

print("Predicted values:", yhat[0:4])
print("True values:", y_test[0:4].values)

PollyPlot(x_train[['horsepower']], x_test[['horsepower']], y_train, y_test, poly,pr)

poly.score(x_train_pr, y_train)

poly.score(x_test_pr, y_test) # A negative R^2 means overfitting

#grafico para ver como cambia el R^2 segun el orden del polinomio

Rsqu_test = []

order = [1, 2, 3, 4]
for n in order:
    pr = PolynomialFeatures(degree=n)
    
    x_train_pr = pr.fit_transform(x_train[['horsepower']])
    
    x_test_pr = pr.fit_transform(x_test[['horsepower']])    
    
    lr.fit(x_train_pr, y_train)
    
    Rsqu_test.append(lr.score(x_test_pr, y_test))

plt.plot(order, Rsqu_test)
plt.xlabel('order')
plt.ylabel('R^2')
plt.title('R^2 Using Test Data')
plt.text(3, 0.75, 'Maximum R^2 ')

"""Grafico interactivo para ver como performa el R^2 segun la cantidad de data para prueba y entrenamiento y el orden del polinomio"""

def f(order, test_data):
    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=test_data, random_state=0)
    pr = PolynomialFeatures(degree=order)
    x_train_pr = pr.fit_transform(x_train[['horsepower']])
    x_test_pr = pr.fit_transform(x_test[['horsepower']])
    poly = LinearRegression()
    poly.fit(x_train_pr,y_train)
    PollyPlot(x_train[['horsepower']], x_test[['horsepower']], y_train,y_test, poly, pr)

interact(f, order=(0, 6, 1), test_data=(0.05, 0.95, 0.05))